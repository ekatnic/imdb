{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMDB 5000 Movies - 502 Final Project - Ethan Katnic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "I found this dataset on Kaggle.com from the following link as I searched for interesting datasets: https://cosmos11.osdinfra.net/cosmos/User360_Shared/my/PracticeQuery/test1.ss\n",
    "\n",
    "I found this dataset to be fairly reputable based on the fact that it is curated by both TheMovieDB and Kaggle itself in tandem, as opposed to being generated by just a single individual. It also has over 650,000 views and nearly 100,000 downloads, so it is quite a popular dataset on the Kaggle forum. \n",
    "\n",
    "The data in this dataset is pulled from the API of TheMovieDB at https://www.themoviedb.org/. The Python script that was used to query the API can be found here: https://gist.github.com/SohierDane/4a84cb96d220fc4791f52562be37968b. This is a popular and well-documented API that I have personally used before. \n",
    "\n",
    "The columns of the data that I used are the following: \n",
    "\n",
    "* **budget**     - numeric dollars\n",
    "\n",
    "* **genres**     - JSON of genres of the film\n",
    "\n",
    "* **original_language** - Original spoken language of the film\n",
    "\n",
    "* **popularity** - Relative popularity compared to all other movies\n",
    "\n",
    "* **production_company** - JSON list of production companies associated with film\n",
    "\n",
    "* **production_countries** - JSON list of where film was produced\n",
    "\n",
    "* **release_date**- *year-month-day* of film release date\n",
    "\n",
    "* **revenue**    - Revenue of film in dollars\n",
    "\n",
    "* **runtime**    - Runtime in minutes\n",
    "\n",
    "* **title**      - Title of movie\n",
    "\n",
    "* **vote_average** - Average rating vote score (1-10)\n",
    "\n",
    "* **vote_count** - Total number of votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and clean dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unusable columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tmdb_5000_movies.csv\")\n",
    "# Drop unusuable columns\n",
    "df = df.drop([\"homepage\",\"id\", \"tagline\",\"status\", \"overview\", \"spoken_languages\", \"original_title\", \"keywords\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column headers do not need reformatting. All in proper column_name form\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must parse the JSON columns (genres, production companies, production countries,\n",
    "# to extract primary genre/prod company/country)\n",
    "primary_genre = []\n",
    "for movie in df.genres:\n",
    "    if(len(ast.literal_eval(movie)) > 0):\n",
    "        primary_genre.append(ast.literal_eval(movie)[0][\"name\"])\n",
    "    else:\n",
    "        primary_genre.append(np.nan)\n",
    "    \n",
    "primary_production = []\n",
    "for movie in df.production_companies:\n",
    "    if(len(ast.literal_eval(movie)) > 0):\n",
    "        primary_production.append(ast.literal_eval(movie)[0][\"name\"])\n",
    "    else:\n",
    "        primary_production.append(np.nan)\n",
    "\n",
    "prod_country_iso = []\n",
    "for movie in df.production_countries:\n",
    "    if(len(ast.literal_eval(movie)) > 0):\n",
    "        prod_country_iso.append(ast.literal_eval(movie)[0]['iso_3166_1'])\n",
    "    else:\n",
    "        prod_country_iso.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create primary genre/production/production country columns and drop old JSON\n",
    "df[\"primary_genre\"] = primary_genre\n",
    "df[\"primary_prod\"] = primary_production\n",
    "df[\"prod_country_iso\"] = prod_country_iso\n",
    "df = df.drop([\"genres\", \"production_companies\", \"production_countries\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle nan and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISSUE: Budget and revenue are often 0, essentially serving as NA\n",
    "print(\"Missing Values: \")\n",
    "print(\"Budget:\" , df[df.budget==0].budget.count())\n",
    "print(\"Revenue:\", df[df.revenue==0].revenue.count())\n",
    "print(\"Runtime:\", df[df.runtime==0].runtime.count())\n",
    "print(\"NAs:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values with nan and impute two null runtimes with average runtime\n",
    "df.loc[df['runtime'] == 0, 'runtime'] = np.nan\n",
    "df.loc[df['budget'] == 0, 'budget'] = np.nan\n",
    "df.loc[df['revenue'] == 0, 'revenue'] = np.nan\n",
    "df.runtime = df.runtime.fillna(df.runtime.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.groupby('primary_genre').count().title.sort_values(ascending=False).head(5), \"\\n\")\n",
    "print(df.groupby('prod_country_iso').count().title.sort_values(ascending=False).head(5),\"\\n\")\n",
    "print(df.groupby('primary_prod').count().title.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are only 27 missing genres, and the vast majority of films are produced in the US, \n",
    "# replace the missing primary genre and missing production countries with the mode of each\n",
    "df.primary_genre = df.primary_genre.fillna(df['primary_genre'].mode()[0])\n",
    "df.prod_country_iso = df.prod_country_iso.fillna(df['prod_country_iso'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the single null release date, as this is difficult to impute\n",
    "df = df[df['release_date'].notnull()]\n",
    "# Additionally, drop the ~350 rows with missing primary production companies, as this too is\n",
    "# difficult to impute with the way that the produciton companies are distributed\n",
    "df = df[df['primary_prod'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing Values: \")\n",
    "print(\"Budget:\" , df[df.budget==0].budget.count())\n",
    "print(\"Revenue:\", df[df.revenue==0].revenue.count())\n",
    "print(\"Runtime:\", df[df.runtime==0].runtime.count())\n",
    "print(\"NAs:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, since the financial data (budget and revenue) is missing from almost 20% of the rows,\n",
    "# I chose to drop these rows instead of imputing them, as I felt that using mean of budget and revenue\n",
    "# would not be an accurate way to fill these values given the variation in both of these fields.\n",
    "df_imputed = df_imputed[df_imputed['budget'].notnull()]\n",
    "df_imputed = df_imputed[df_imputed['revenue'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing Values: \")\n",
    "print(\"Budget:\" , df_imputed[df_imputed.budget==0].budget.count())\n",
    "print(\"Revenue:\", df_imputed[df_imputed.revenue==0].revenue.count())\n",
    "print(\"Runtime:\", df_imputed[df_imputed.runtime==0].runtime.count())\n",
    "print(\"NAs:\")\n",
    "print(df_imputed.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upon inspecting production company, there are hundreds and hundreds of companies that have only produced one movie.\n",
    "# This is problematic, as I do not want a dummy variable for every one of these small production companies.\n",
    "# As an alternative, I replaced all production companies that have produced fewer than 10 movies with \"Small Production Company\"\n",
    "df_imputed['prod_company_movie_count'] = df.groupby('primary_prod')['title'].transform(len)\n",
    "df_imputed.loc[df_imputed.prod_company_movie_count < 10, 'primary_prod'] = \"Small Production Company\"\n",
    "df_imputed = df_imputed.drop(\"prod_company_movie_count\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed.groupby(['primary_prod'])['title'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed[df.primary_prod == \"Fine Line Features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "df_imputed.select_dtypes(exclude=numerics).drop([\"title\",\"release_date\"], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data=df_imputed, columns=['original_language', 'primary_genre', 'primary_prod', \"prod_country_iso\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prod_country = df_imputed.groupby('primary_prod').count()\n",
    "(num_prod_country[num_prod_country.budget > 0].budget).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "reg = smf.ols(\"vote_average~\", age_data).fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
